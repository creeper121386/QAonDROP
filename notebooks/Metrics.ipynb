{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_pretrained_bert import BertModel, BertTokenizer \n",
    "import torch\n",
    "import sys\n",
    "from allennlp.models.model import Model\n",
    "from allennlp.training.metrics.drop_em_and_f1 import DropEmAndF1\n",
    "from allennlp.data.token_indexers.wordpiece_indexer import WordpieceIndexer\n",
    "from allennlp.data.iterators.bucket_iterator import BucketIterator\n",
    "from allennlp.data.iterators.basic_iterator import BasicIterator\n",
    "from allennlp.data.vocabulary import Vocabulary\n",
    "from allennlp.training.trainer import Trainer\n",
    "from allennlp.nn.util import move_to_device\n",
    "from typing import Sequence, Union\n",
    "from tqdm import tqdm\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from drop_bert.data_processing import BertDropTokenizer, BertDropReader, BertDropTokenIndexer\n",
    "import drop_bert.nhelpers\n",
    "from drop_bert.augmented_bert_templated_old import NumericallyAugmentedBERTT\n",
    "from drop_bert.augmented_bert_plus_old import NumericallyAugmentedBERTPlus\n",
    "from drop_bert.augmented_bert_old import NumericallyAugmentedBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_num = 0\n",
    "device = torch.device('cuda:%d' % device_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "def filter_by_answer_choice(abert, model, reader, answer_type):\n",
    "    abert.load_state_dict(torch.load(model, map_location=device))\n",
    "    abert.to(device)\n",
    "    abert.eval()\n",
    "    \n",
    "    reader.answer_type = answer_type\n",
    "    dev = reader.read('data/drop_dataset_dev.json')\n",
    "    iterator = BasicIterator(batch_size = 1)\n",
    "    iterator.index_with(Vocabulary())\n",
    "\n",
    "    dev_iter = iterator(dev, num_epochs=1)\n",
    "    dev_batches = [batch for batch in dev_iter]\n",
    "    dev_batches = move_to_device(dev_batches, device_num)\n",
    "    \n",
    "    filtered = defaultdict(list)\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dev_batches):\n",
    "            out = abert(**batch)\n",
    "            for i, answer in enumerate(out[\"answer\"]):\n",
    "                filtered[answer['answer_type']].append(batch)\n",
    "    torch.cuda.empty_cache()\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "def get_metrics(abert, model, batches, answer_type, answer_choice):\n",
    "    abert.load_state_dict(torch.load(model, map_location=device))\n",
    "    abert.to(device)\n",
    "    abert.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(batches):\n",
    "            abert(**batch)\n",
    "        print(answer_type, answer_choice, len(batches), abert._drop_metrics.get_metric())\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = {}\n",
    "tokenizer = BertDropTokenizer('bert-base-uncased')\n",
    "token_indexer = BertDropTokenIndexer('bert-base-uncased')\n",
    "abert = NumericallyAugmentedBERTT(Vocabulary(), 'bert-base-uncased', special_numbers=[100, 1])\n",
    "reader = BertDropReader(tokenizer, {'tokens': token_indexer}, \n",
    "                        extra_numbers=[100, 1], exp_search='template')\n",
    "model = '/home/ubuntu/storage/nabert_t_full_attn/best.th'\n",
    "filtered['all'] = filter_by_answer_choice(abert, model, reader, None)\n",
    "filtered['date'] = filter_by_answer_choice(abert, model, reader, ['date'])\n",
    "filtered['multiple_span'] = filter_by_answer_choice(abert, model, reader, ['multiple_span'])\n",
    "filtered['single_span'] = filter_by_answer_choice(abert, model, reader, ['single_span'])\n",
    "filtered['number'] = filter_by_answer_choice(abert, model, reader, ['number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for answer_type in filtered:\n",
    "    full = []\n",
    "    for answer_choice in filtered[answer_type]:\n",
    "        full += filtered[answer_type][answer_choice]\n",
    "        print(answer_type, answer_choice)\n",
    "        get_metrics(model, filtered[answer_type][answer_choice], answer_type, answer_choice)\n",
    "    get_metrics(model, full, answer_type, 'all')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
