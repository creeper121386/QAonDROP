{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-13 02:40:02,925 - INFO - pytorch_pretrained_bert.modeling - Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n",
      "/data/anaconda/envs/allennlp/lib/python3.6/site-packages/sklearn/utils/linear_assignment_.py:21: DeprecationWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
      "  DeprecationWarning)\n",
      "2019-05-13 02:40:03,908 - INFO - allennlp.common.params - random_seed = 13370\n",
      "2019-05-13 02:40:03,909 - INFO - allennlp.common.params - numpy_seed = 1337\n",
      "2019-05-13 02:40:03,909 - INFO - allennlp.common.params - pytorch_seed = 133\n",
      "2019-05-13 02:40:03,935 - INFO - allennlp.common.checks - Pytorch version: 1.1.0\n",
      "2019-05-13 02:40:03,940 - INFO - allennlp.common.params - evaluate_on_test = False\n",
      "2019-05-13 02:40:03,940 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'extra_numbers': [100, 1], 'token_indexers': {'tokens': {'pretrained_model': 'bert-base-uncased', 'type': 'bert-drop'}}, 'tokenizer': {'pretrained_model': 'bert-base-uncased', 'type': 'bert-drop'}, 'type': 'bert-drop'} and extras set()\n",
      "2019-05-13 02:40:03,940 - INFO - allennlp.common.params - dataset_reader.type = bert-drop\n",
      "2019-05-13 02:40:03,941 - INFO - allennlp.common.from_params - instantiating class <class 'drop_bert.data_processing.BertDropReader'> from params {'extra_numbers': [100, 1], 'token_indexers': {'tokens': {'pretrained_model': 'bert-base-uncased', 'type': 'bert-drop'}}, 'tokenizer': {'pretrained_model': 'bert-base-uncased', 'type': 'bert-drop'}} and extras set()\n",
      "2019-05-13 02:40:03,941 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.tokenizers.tokenizer.Tokenizer'> from params {'pretrained_model': 'bert-base-uncased', 'type': 'bert-drop'} and extras set()\n",
      "2019-05-13 02:40:03,941 - INFO - allennlp.common.params - dataset_reader.tokenizer.type = bert-drop\n",
      "2019-05-13 02:40:03,941 - INFO - allennlp.common.from_params - instantiating class <class 'drop_bert.data_processing.BertDropTokenizer'> from params {'pretrained_model': 'bert-base-uncased'} and extras set()\n",
      "2019-05-13 02:40:03,941 - INFO - allennlp.common.params - dataset_reader.tokenizer.pretrained_model = bert-base-uncased\n",
      "2019-05-13 02:40:04,257 - INFO - pytorch_pretrained_bert.tokenization - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/ubuntu/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "2019-05-13 02:40:04,286 - INFO - allennlp.common.from_params - instantiating class allennlp.data.token_indexers.token_indexer.TokenIndexer from params {'pretrained_model': 'bert-base-uncased', 'type': 'bert-drop'} and extras set()\n",
      "2019-05-13 02:40:04,286 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.type = bert-drop\n",
      "2019-05-13 02:40:04,286 - INFO - allennlp.common.from_params - instantiating class drop_bert.data_processing.BertDropTokenIndexer from params {'pretrained_model': 'bert-base-uncased'} and extras set()\n",
      "2019-05-13 02:40:04,286 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.pretrained_model = bert-base-uncased\n",
      "2019-05-13 02:40:04,286 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.max_pieces = 512\n",
      "2019-05-13 02:40:04,573 - INFO - pytorch_pretrained_bert.tokenization - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/ubuntu/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "2019-05-13 02:40:04,604 - INFO - allennlp.common.params - dataset_reader.lazy = False\n",
      "2019-05-13 02:40:04,604 - INFO - allennlp.common.params - dataset_reader.max_pieces = 512\n",
      "2019-05-13 02:40:04,604 - INFO - allennlp.common.params - dataset_reader.max_count = 10\n",
      "2019-05-13 02:40:04,604 - INFO - allennlp.common.params - dataset_reader.max_spans = 10\n",
      "2019-05-13 02:40:04,604 - INFO - allennlp.common.params - dataset_reader.max_numbers_expression = 2\n",
      "2019-05-13 02:40:04,604 - INFO - allennlp.common.params - dataset_reader.answer_type = None\n",
      "2019-05-13 02:40:04,604 - INFO - allennlp.common.params - dataset_reader.use_validated = True\n",
      "2019-05-13 02:40:04,604 - INFO - allennlp.common.params - dataset_reader.wordpiece_numbers = True\n",
      "2019-05-13 02:40:04,604 - INFO - allennlp.common.params - dataset_reader.custom_word_to_num = True\n",
      "2019-05-13 02:40:04,604 - INFO - allennlp.common.params - dataset_reader.exp_search = add_sub\n",
      "2019-05-13 02:40:04,604 - INFO - allennlp.common.params - dataset_reader.max_depth = 3\n",
      "2019-05-13 02:40:04,605 - INFO - allennlp.common.params - dataset_reader.extra_numbers = [100, 1]\n",
      "2019-05-13 02:40:04,752 - INFO - allennlp.common.params - validation_dataset_reader = None\n",
      "2019-05-13 02:40:04,752 - INFO - allennlp.common.params - train_data_path = data/drop_dataset_train.json\n",
      "2019-05-13 02:40:04,752 - INFO - allennlp.training.util - Reading training data from data/drop_dataset_train.json\n",
      "100%|##########| 5565/5565 [02:46<00:00, 33.37it/s]\n",
      "2019-05-13 02:42:52,647 - INFO - allennlp.common.params - validation_data_path = data/drop_dataset_dev.json\n",
      "2019-05-13 02:42:52,647 - INFO - allennlp.training.util - Reading validation data from data/drop_dataset_dev.json\n",
      "100%|##########| 582/582 [00:21<00:00, 26.94it/s]\n",
      "2019-05-13 02:43:14,371 - INFO - allennlp.common.params - test_data_path = None\n",
      "2019-05-13 02:43:14,373 - INFO - allennlp.training.trainer - From dataset instances, train, validation will be considered for vocabulary creation.\n",
      "2019-05-13 02:43:14,373 - INFO - allennlp.common.params - vocabulary.type = None\n",
      "2019-05-13 02:43:14,373 - INFO - allennlp.common.params - vocabulary.extend = False\n",
      "2019-05-13 02:43:14,373 - INFO - allennlp.common.params - vocabulary.directory_path = None\n",
      "2019-05-13 02:43:14,373 - INFO - allennlp.common.params - vocabulary.min_count = None\n",
      "2019-05-13 02:43:14,373 - INFO - allennlp.common.params - vocabulary.max_vocab_size = None\n",
      "2019-05-13 02:43:14,373 - INFO - allennlp.common.params - vocabulary.non_padded_namespaces = ('*tags', '*labels')\n",
      "2019-05-13 02:43:14,373 - INFO - allennlp.common.params - vocabulary.min_pretrained_embeddings = None\n",
      "2019-05-13 02:43:14,373 - INFO - allennlp.common.params - vocabulary.only_include_pretrained_words = False\n",
      "2019-05-13 02:43:14,374 - INFO - allennlp.common.params - vocabulary.tokens_to_add = None\n",
      "2019-05-13 02:43:14,374 - INFO - allennlp.data.vocabulary - Fitting token dictionary from dataset.\n",
      "86945it [00:04, 20065.30it/s]\n",
      "2019-05-13 02:43:18,707 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.models.model.Model'> from params {'bert_pretrained_model': 'bert-base-uncased', 'dropout_prob': 0.1, 'number_rep': 'attention', 'special_numbers': [100, 1], 'type': 'nabert'} and extras {'vocab'}\n",
      "2019-05-13 02:43:18,707 - INFO - allennlp.common.params - model.type = nabert\n",
      "2019-05-13 02:43:18,708 - INFO - allennlp.common.from_params - instantiating class <class 'drop_bert.augmented_bert_plus.NumericallyAugmentedBERTPlus'> from params {'bert_pretrained_model': 'bert-base-uncased', 'dropout_prob': 0.1, 'number_rep': 'attention', 'special_numbers': [100, 1]} and extras {'vocab'}\n",
      "2019-05-13 02:43:18,708 - INFO - allennlp.common.params - model.bert_pretrained_model = bert-base-uncased\n",
      "2019-05-13 02:43:18,708 - INFO - allennlp.common.params - model.dropout_prob = 0.1\n",
      "2019-05-13 02:43:18,708 - INFO - allennlp.common.params - model.max_count = 10\n",
      "2019-05-13 02:43:18,708 - INFO - allennlp.common.params - model.answering_abilities = None\n",
      "2019-05-13 02:43:18,708 - INFO - allennlp.common.params - model.number_rep = attention\n",
      "2019-05-13 02:43:18,708 - INFO - allennlp.common.params - model.arithmetic = base\n",
      "2019-05-13 02:43:18,708 - INFO - allennlp.common.params - model.special_numbers = [100, 1]\n",
      "2019-05-13 02:43:19,008 - INFO - pytorch_pretrained_bert.modeling - loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/ubuntu/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "2019-05-13 02:43:19,009 - INFO - pytorch_pretrained_bert.modeling - extracting archive file /home/ubuntu/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpbm_89n14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-13 02:43:22,734 - INFO - pytorch_pretrained_bert.modeling - Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "2019-05-13 02:43:25,141 - INFO - pytorch_pretrained_bert.tokenization - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/ubuntu/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "2019-05-13 02:43:25,218 - INFO - allennlp.nn.initializers - Initializing parameters\n",
      "2019-05-13 02:43:25,219 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n",
      "2019-05-13 02:43:25,220 - INFO - allennlp.nn.initializers -    BERT.embeddings.LayerNorm.bias\n",
      "2019-05-13 02:43:25,220 - INFO - allennlp.nn.initializers -    BERT.embeddings.LayerNorm.weight\n",
      "2019-05-13 02:43:25,220 - INFO - allennlp.nn.initializers -    BERT.embeddings.position_embeddings.weight\n",
      "2019-05-13 02:43:25,220 - INFO - allennlp.nn.initializers -    BERT.embeddings.token_type_embeddings.weight\n",
      "2019-05-13 02:43:25,220 - INFO - allennlp.nn.initializers -    BERT.embeddings.word_embeddings.weight\n",
      "2019-05-13 02:43:25,220 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "2019-05-13 02:43:25,220 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "2019-05-13 02:43:25,220 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.0.attention.output.dense.bias\n",
      "2019-05-13 02:43:25,220 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.0.attention.output.dense.weight\n",
      "2019-05-13 02:43:25,220 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.0.attention.self.key.bias\n",
      "2019-05-13 02:43:25,220 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.0.attention.self.key.weight\n",
      "2019-05-13 02:43:25,220 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.0.attention.self.query.bias\n",
      "2019-05-13 02:43:25,220 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.0.attention.self.query.weight\n",
      "2019-05-13 02:43:25,221 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.0.attention.self.value.bias\n",
      "2019-05-13 02:43:25,221 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.0.attention.self.value.weight\n",
      "2019-05-13 02:43:25,221 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.0.intermediate.dense.bias\n",
      "2019-05-13 02:43:25,221 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.0.intermediate.dense.weight\n",
      "2019-05-13 02:43:25,221 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.0.output.LayerNorm.bias\n",
      "2019-05-13 02:43:25,221 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.0.output.LayerNorm.weight\n",
      "2019-05-13 02:43:25,221 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.0.output.dense.bias\n",
      "2019-05-13 02:43:25,221 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.0.output.dense.weight\n",
      "2019-05-13 02:43:25,221 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "2019-05-13 02:43:25,221 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "2019-05-13 02:43:25,221 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.1.attention.output.dense.bias\n",
      "2019-05-13 02:43:25,221 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.1.attention.output.dense.weight\n",
      "2019-05-13 02:43:25,221 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.1.attention.self.key.bias\n",
      "2019-05-13 02:43:25,222 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.1.attention.self.key.weight\n",
      "2019-05-13 02:43:25,222 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.1.attention.self.query.bias\n",
      "2019-05-13 02:43:25,222 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.1.attention.self.query.weight\n",
      "2019-05-13 02:43:25,222 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.1.attention.self.value.bias\n",
      "2019-05-13 02:43:25,222 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.1.attention.self.value.weight\n",
      "2019-05-13 02:43:25,222 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.1.intermediate.dense.bias\n",
      "2019-05-13 02:43:25,222 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.1.intermediate.dense.weight\n",
      "2019-05-13 02:43:25,222 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.1.output.LayerNorm.bias\n",
      "2019-05-13 02:43:25,222 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.1.output.LayerNorm.weight\n",
      "2019-05-13 02:43:25,222 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.1.output.dense.bias\n",
      "2019-05-13 02:43:25,222 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.1.output.dense.weight\n",
      "2019-05-13 02:43:25,222 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "2019-05-13 02:43:25,222 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "2019-05-13 02:43:25,223 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.10.attention.output.dense.bias\n",
      "2019-05-13 02:43:25,223 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.10.attention.output.dense.weight\n",
      "2019-05-13 02:43:25,223 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.10.attention.self.key.bias\n",
      "2019-05-13 02:43:25,223 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.10.attention.self.key.weight\n",
      "2019-05-13 02:43:25,223 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.10.attention.self.query.bias\n",
      "2019-05-13 02:43:25,223 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.10.attention.self.query.weight\n",
      "2019-05-13 02:43:25,223 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.10.attention.self.value.bias\n",
      "2019-05-13 02:43:25,223 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.10.attention.self.value.weight\n",
      "2019-05-13 02:43:25,223 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.10.intermediate.dense.bias\n",
      "2019-05-13 02:43:25,223 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.10.intermediate.dense.weight\n",
      "2019-05-13 02:43:25,223 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.10.output.LayerNorm.bias\n",
      "2019-05-13 02:43:25,223 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.10.output.LayerNorm.weight\n",
      "2019-05-13 02:43:25,223 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.10.output.dense.bias\n",
      "2019-05-13 02:43:25,223 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.10.output.dense.weight\n",
      "2019-05-13 02:43:25,224 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "2019-05-13 02:43:25,224 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "2019-05-13 02:43:25,224 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.11.attention.output.dense.bias\n",
      "2019-05-13 02:43:25,224 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.11.attention.output.dense.weight\n",
      "2019-05-13 02:43:25,224 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.11.attention.self.key.bias\n",
      "2019-05-13 02:43:25,224 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.11.attention.self.key.weight\n",
      "2019-05-13 02:43:25,224 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.11.attention.self.query.bias\n",
      "2019-05-13 02:43:25,224 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.11.attention.self.query.weight\n",
      "2019-05-13 02:43:25,224 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.11.attention.self.value.bias\n",
      "2019-05-13 02:43:25,224 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.11.attention.self.value.weight\n",
      "2019-05-13 02:43:25,224 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.11.intermediate.dense.bias\n",
      "2019-05-13 02:43:25,224 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.11.intermediate.dense.weight\n",
      "2019-05-13 02:43:25,224 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.11.output.LayerNorm.bias\n",
      "2019-05-13 02:43:25,224 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.11.output.LayerNorm.weight\n",
      "2019-05-13 02:43:25,225 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.11.output.dense.bias\n",
      "2019-05-13 02:43:25,225 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.11.output.dense.weight\n",
      "2019-05-13 02:43:25,225 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "2019-05-13 02:43:25,225 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "2019-05-13 02:43:25,225 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.2.attention.output.dense.bias\n",
      "2019-05-13 02:43:25,225 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.2.attention.output.dense.weight\n",
      "2019-05-13 02:43:25,225 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.2.attention.self.key.bias\n",
      "2019-05-13 02:43:25,225 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.2.attention.self.key.weight\n",
      "2019-05-13 02:43:25,225 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.2.attention.self.query.bias\n",
      "2019-05-13 02:43:25,225 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.2.attention.self.query.weight\n",
      "2019-05-13 02:43:25,225 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.2.attention.self.value.bias\n",
      "2019-05-13 02:43:25,225 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.2.attention.self.value.weight\n",
      "2019-05-13 02:43:25,226 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.2.intermediate.dense.bias\n",
      "2019-05-13 02:43:25,226 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.2.intermediate.dense.weight\n",
      "2019-05-13 02:43:25,226 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.2.output.LayerNorm.bias\n",
      "2019-05-13 02:43:25,226 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.2.output.LayerNorm.weight\n",
      "2019-05-13 02:43:25,226 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.2.output.dense.bias\n",
      "2019-05-13 02:43:25,226 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.2.output.dense.weight\n",
      "2019-05-13 02:43:25,226 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "2019-05-13 02:43:25,226 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "2019-05-13 02:43:25,226 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.3.attention.output.dense.bias\n",
      "2019-05-13 02:43:25,227 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.3.attention.output.dense.weight\n",
      "2019-05-13 02:43:25,227 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.3.attention.self.key.bias\n",
      "2019-05-13 02:43:25,227 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.3.attention.self.key.weight\n",
      "2019-05-13 02:43:25,227 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.3.attention.self.query.bias\n",
      "2019-05-13 02:43:25,227 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.3.attention.self.query.weight\n",
      "2019-05-13 02:43:25,227 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.3.attention.self.value.bias\n",
      "2019-05-13 02:43:25,227 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.3.attention.self.value.weight\n",
      "2019-05-13 02:43:25,227 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.3.intermediate.dense.bias\n",
      "2019-05-13 02:43:25,227 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.3.intermediate.dense.weight\n",
      "2019-05-13 02:43:25,227 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.3.output.LayerNorm.bias\n",
      "2019-05-13 02:43:25,227 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.3.output.LayerNorm.weight\n",
      "2019-05-13 02:43:25,227 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.3.output.dense.bias\n",
      "2019-05-13 02:43:25,227 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.3.output.dense.weight\n",
      "2019-05-13 02:43:25,228 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "2019-05-13 02:43:25,228 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "2019-05-13 02:43:25,228 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.4.attention.output.dense.bias\n",
      "2019-05-13 02:43:25,228 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.4.attention.output.dense.weight\n",
      "2019-05-13 02:43:25,228 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.4.attention.self.key.bias\n",
      "2019-05-13 02:43:25,228 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.4.attention.self.key.weight\n",
      "2019-05-13 02:43:25,228 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.4.attention.self.query.bias\n",
      "2019-05-13 02:43:25,228 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.4.attention.self.query.weight\n",
      "2019-05-13 02:43:25,228 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.4.attention.self.value.bias\n",
      "2019-05-13 02:43:25,228 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.4.attention.self.value.weight\n",
      "2019-05-13 02:43:25,228 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.4.intermediate.dense.bias\n",
      "2019-05-13 02:43:25,228 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.4.intermediate.dense.weight\n",
      "2019-05-13 02:43:25,228 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.4.output.LayerNorm.bias\n",
      "2019-05-13 02:43:25,229 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.4.output.LayerNorm.weight\n",
      "2019-05-13 02:43:25,229 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.4.output.dense.bias\n",
      "2019-05-13 02:43:25,229 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.4.output.dense.weight\n",
      "2019-05-13 02:43:25,229 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "2019-05-13 02:43:25,229 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "2019-05-13 02:43:25,229 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.5.attention.output.dense.bias\n",
      "2019-05-13 02:43:25,229 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.5.attention.output.dense.weight\n",
      "2019-05-13 02:43:25,229 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.5.attention.self.key.bias\n",
      "2019-05-13 02:43:25,229 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.5.attention.self.key.weight\n",
      "2019-05-13 02:43:25,229 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.5.attention.self.query.bias\n",
      "2019-05-13 02:43:25,229 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.5.attention.self.query.weight\n",
      "2019-05-13 02:43:25,229 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.5.attention.self.value.bias\n",
      "2019-05-13 02:43:25,229 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.5.attention.self.value.weight\n",
      "2019-05-13 02:43:25,230 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.5.intermediate.dense.bias\n",
      "2019-05-13 02:43:25,230 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.5.intermediate.dense.weight\n",
      "2019-05-13 02:43:25,230 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.5.output.LayerNorm.bias\n",
      "2019-05-13 02:43:25,230 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.5.output.LayerNorm.weight\n",
      "2019-05-13 02:43:25,230 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.5.output.dense.bias\n",
      "2019-05-13 02:43:25,230 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.5.output.dense.weight\n",
      "2019-05-13 02:43:25,230 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.6.attention.output.LayerNorm.bias\n",
      "2019-05-13 02:43:25,230 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.6.attention.output.LayerNorm.weight\n",
      "2019-05-13 02:43:25,230 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.6.attention.output.dense.bias\n",
      "2019-05-13 02:43:25,230 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.6.attention.output.dense.weight\n",
      "2019-05-13 02:43:25,230 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.6.attention.self.key.bias\n",
      "2019-05-13 02:43:25,230 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.6.attention.self.key.weight\n",
      "2019-05-13 02:43:25,230 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.6.attention.self.query.bias\n",
      "2019-05-13 02:43:25,231 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.6.attention.self.query.weight\n",
      "2019-05-13 02:43:25,231 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.6.attention.self.value.bias\n",
      "2019-05-13 02:43:25,231 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.6.attention.self.value.weight\n",
      "2019-05-13 02:43:25,231 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.6.intermediate.dense.bias\n",
      "2019-05-13 02:43:25,231 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.6.intermediate.dense.weight\n",
      "2019-05-13 02:43:25,231 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.6.output.LayerNorm.bias\n",
      "2019-05-13 02:43:25,231 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.6.output.LayerNorm.weight\n",
      "2019-05-13 02:43:25,231 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.6.output.dense.bias\n",
      "2019-05-13 02:43:25,231 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.6.output.dense.weight\n",
      "2019-05-13 02:43:25,231 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.7.attention.output.LayerNorm.bias\n",
      "2019-05-13 02:43:25,231 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.7.attention.output.LayerNorm.weight\n",
      "2019-05-13 02:43:25,231 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.7.attention.output.dense.bias\n",
      "2019-05-13 02:43:25,231 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.7.attention.output.dense.weight\n",
      "2019-05-13 02:43:25,231 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.7.attention.self.key.bias\n",
      "2019-05-13 02:43:25,232 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.7.attention.self.key.weight\n",
      "2019-05-13 02:43:25,232 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.7.attention.self.query.bias\n",
      "2019-05-13 02:43:25,232 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.7.attention.self.query.weight\n",
      "2019-05-13 02:43:25,232 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.7.attention.self.value.bias\n",
      "2019-05-13 02:43:25,232 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.7.attention.self.value.weight\n",
      "2019-05-13 02:43:25,232 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.7.intermediate.dense.bias\n",
      "2019-05-13 02:43:25,232 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.7.intermediate.dense.weight\n",
      "2019-05-13 02:43:25,232 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.7.output.LayerNorm.bias\n",
      "2019-05-13 02:43:25,232 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.7.output.LayerNorm.weight\n",
      "2019-05-13 02:43:25,232 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.7.output.dense.bias\n",
      "2019-05-13 02:43:25,232 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.7.output.dense.weight\n",
      "2019-05-13 02:43:25,232 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.8.attention.output.LayerNorm.bias\n",
      "2019-05-13 02:43:25,232 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.8.attention.output.LayerNorm.weight\n",
      "2019-05-13 02:43:25,232 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.8.attention.output.dense.bias\n",
      "2019-05-13 02:43:25,233 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.8.attention.output.dense.weight\n",
      "2019-05-13 02:43:25,233 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.8.attention.self.key.bias\n",
      "2019-05-13 02:43:25,233 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.8.attention.self.key.weight\n",
      "2019-05-13 02:43:25,233 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.8.attention.self.query.bias\n",
      "2019-05-13 02:43:25,233 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.8.attention.self.query.weight\n",
      "2019-05-13 02:43:25,233 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.8.attention.self.value.bias\n",
      "2019-05-13 02:43:25,233 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.8.attention.self.value.weight\n",
      "2019-05-13 02:43:25,233 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.8.intermediate.dense.bias\n",
      "2019-05-13 02:43:25,233 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.8.intermediate.dense.weight\n",
      "2019-05-13 02:43:25,233 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.8.output.LayerNorm.bias\n",
      "2019-05-13 02:43:25,233 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.8.output.LayerNorm.weight\n",
      "2019-05-13 02:43:25,233 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.8.output.dense.bias\n",
      "2019-05-13 02:43:25,233 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.8.output.dense.weight\n",
      "2019-05-13 02:43:25,234 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.9.attention.output.LayerNorm.bias\n",
      "2019-05-13 02:43:25,234 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.9.attention.output.LayerNorm.weight\n",
      "2019-05-13 02:43:25,234 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.9.attention.output.dense.bias\n",
      "2019-05-13 02:43:25,234 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.9.attention.output.dense.weight\n",
      "2019-05-13 02:43:25,234 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.9.attention.self.key.bias\n",
      "2019-05-13 02:43:25,234 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.9.attention.self.key.weight\n",
      "2019-05-13 02:43:25,234 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.9.attention.self.query.bias\n",
      "2019-05-13 02:43:25,234 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.9.attention.self.query.weight\n",
      "2019-05-13 02:43:25,234 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.9.attention.self.value.bias\n",
      "2019-05-13 02:43:25,234 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.9.attention.self.value.weight\n",
      "2019-05-13 02:43:25,234 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.9.intermediate.dense.bias\n",
      "2019-05-13 02:43:25,234 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.9.intermediate.dense.weight\n",
      "2019-05-13 02:43:25,234 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.9.output.LayerNorm.bias\n",
      "2019-05-13 02:43:25,234 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.9.output.LayerNorm.weight\n",
      "2019-05-13 02:43:25,235 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.9.output.dense.bias\n",
      "2019-05-13 02:43:25,235 - INFO - allennlp.nn.initializers -    BERT.encoder.layer.9.output.dense.weight\n",
      "2019-05-13 02:43:25,235 - INFO - allennlp.nn.initializers -    BERT.pooler.dense.bias\n",
      "2019-05-13 02:43:25,235 - INFO - allennlp.nn.initializers -    BERT.pooler.dense.weight\n",
      "2019-05-13 02:43:25,235 - INFO - allennlp.nn.initializers -    _answer_ability_predictor.0.bias\n",
      "2019-05-13 02:43:25,235 - INFO - allennlp.nn.initializers -    _answer_ability_predictor.0.weight\n",
      "2019-05-13 02:43:25,235 - INFO - allennlp.nn.initializers -    _answer_ability_predictor.3.bias\n",
      "2019-05-13 02:43:25,235 - INFO - allennlp.nn.initializers -    _answer_ability_predictor.3.weight\n",
      "2019-05-13 02:43:25,235 - INFO - allennlp.nn.initializers -    _arithmetic_passage_weight_predictor.bias\n",
      "2019-05-13 02:43:25,235 - INFO - allennlp.nn.initializers -    _arithmetic_passage_weight_predictor.weight\n",
      "2019-05-13 02:43:25,235 - INFO - allennlp.nn.initializers -    _arithmetic_weights_predictor.bias\n",
      "2019-05-13 02:43:25,236 - INFO - allennlp.nn.initializers -    _arithmetic_weights_predictor.weight\n",
      "2019-05-13 02:43:25,236 - INFO - allennlp.nn.initializers -    _count_number_predictor.0.bias\n",
      "2019-05-13 02:43:25,236 - INFO - allennlp.nn.initializers -    _count_number_predictor.0.weight\n",
      "2019-05-13 02:43:25,236 - INFO - allennlp.nn.initializers -    _count_number_predictor.3.bias\n",
      "2019-05-13 02:43:25,236 - INFO - allennlp.nn.initializers -    _count_number_predictor.3.weight\n",
      "2019-05-13 02:43:25,236 - INFO - allennlp.nn.initializers -    _count_passage_weight_predictor.bias\n",
      "2019-05-13 02:43:25,236 - INFO - allennlp.nn.initializers -    _count_passage_weight_predictor.weight\n",
      "2019-05-13 02:43:25,236 - INFO - allennlp.nn.initializers -    _number_sign_predictor.0.bias\n",
      "2019-05-13 02:43:25,236 - INFO - allennlp.nn.initializers -    _number_sign_predictor.0.weight\n",
      "2019-05-13 02:43:25,236 - INFO - allennlp.nn.initializers -    _number_sign_predictor.3.bias\n",
      "2019-05-13 02:43:25,236 - INFO - allennlp.nn.initializers -    _number_sign_predictor.3.weight\n",
      "2019-05-13 02:43:25,236 - INFO - allennlp.nn.initializers -    _number_weights_predictor.bias\n",
      "2019-05-13 02:43:25,236 - INFO - allennlp.nn.initializers -    _number_weights_predictor.weight\n",
      "2019-05-13 02:43:25,236 - INFO - allennlp.nn.initializers -    _passage_span_end_predictor.bias\n",
      "2019-05-13 02:43:25,236 - INFO - allennlp.nn.initializers -    _passage_span_end_predictor.weight\n",
      "2019-05-13 02:43:25,237 - INFO - allennlp.nn.initializers -    _passage_span_start_predictor.bias\n",
      "2019-05-13 02:43:25,237 - INFO - allennlp.nn.initializers -    _passage_span_start_predictor.weight\n",
      "2019-05-13 02:43:25,237 - INFO - allennlp.nn.initializers -    _passage_weights_predictor.bias\n",
      "2019-05-13 02:43:25,237 - INFO - allennlp.nn.initializers -    _passage_weights_predictor.weight\n",
      "2019-05-13 02:43:25,237 - INFO - allennlp.nn.initializers -    _qspan_passage_weight_predictor.bias\n",
      "2019-05-13 02:43:25,237 - INFO - allennlp.nn.initializers -    _qspan_passage_weight_predictor.weight\n",
      "2019-05-13 02:43:25,237 - INFO - allennlp.nn.initializers -    _question_span_end_predictor.0.bias\n",
      "2019-05-13 02:43:25,237 - INFO - allennlp.nn.initializers -    _question_span_end_predictor.0.weight\n",
      "2019-05-13 02:43:25,237 - INFO - allennlp.nn.initializers -    _question_span_end_predictor.3.bias\n",
      "2019-05-13 02:43:25,237 - INFO - allennlp.nn.initializers -    _question_span_end_predictor.3.weight\n",
      "2019-05-13 02:43:25,237 - INFO - allennlp.nn.initializers -    _question_span_start_predictor.0.bias\n",
      "2019-05-13 02:43:25,237 - INFO - allennlp.nn.initializers -    _question_span_start_predictor.0.weight\n",
      "2019-05-13 02:43:25,237 - INFO - allennlp.nn.initializers -    _question_span_start_predictor.3.bias\n",
      "2019-05-13 02:43:25,237 - INFO - allennlp.nn.initializers -    _question_span_start_predictor.3.weight\n",
      "2019-05-13 02:43:25,238 - INFO - allennlp.nn.initializers -    _question_weights_predictor.bias\n",
      "2019-05-13 02:43:25,238 - INFO - allennlp.nn.initializers -    _question_weights_predictor.weight\n",
      "2019-05-13 02:43:25,238 - INFO - allennlp.nn.initializers -    special_embedding.weight\n",
      "2019-05-13 02:43:25,239 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.iterators.data_iterator.DataIterator'> from params {'batch_size': 4, 'type': 'basic'} and extras set()\n",
      "2019-05-13 02:43:25,239 - INFO - allennlp.common.params - iterator.type = basic\n",
      "2019-05-13 02:43:25,239 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.iterators.basic_iterator.BasicIterator'> from params {'batch_size': 4} and extras set()\n",
      "2019-05-13 02:43:25,239 - INFO - allennlp.common.params - iterator.batch_size = 4\n",
      "2019-05-13 02:43:25,240 - INFO - allennlp.common.params - iterator.instances_per_epoch = None\n",
      "2019-05-13 02:43:25,240 - INFO - allennlp.common.params - iterator.max_instances_in_memory = None\n",
      "2019-05-13 02:43:25,240 - INFO - allennlp.common.params - iterator.cache_instances = False\n",
      "2019-05-13 02:43:25,240 - INFO - allennlp.common.params - iterator.track_epoch = False\n",
      "2019-05-13 02:43:25,240 - INFO - allennlp.common.params - iterator.maximum_samples_per_batch = None\n",
      "2019-05-13 02:43:25,240 - INFO - allennlp.common.params - validation_iterator = None\n",
      "2019-05-13 02:43:25,240 - INFO - allennlp.common.params - trainer.no_grad = ()\n",
      "2019-05-13 02:43:25,242 - INFO - allennlp.training.trainer - Following parameters are Frozen  (without gradient):\n",
      "2019-05-13 02:43:25,242 - INFO - allennlp.training.trainer - Following parameters are Tunable (with gradient):\n",
      "2019-05-13 02:43:25,242 - INFO - allennlp.training.trainer - BERT.embeddings.word_embeddings.weight\n",
      "2019-05-13 02:43:25,242 - INFO - allennlp.training.trainer - BERT.embeddings.position_embeddings.weight\n",
      "2019-05-13 02:43:25,242 - INFO - allennlp.training.trainer - BERT.embeddings.token_type_embeddings.weight\n",
      "2019-05-13 02:43:25,242 - INFO - allennlp.training.trainer - BERT.embeddings.LayerNorm.weight\n",
      "2019-05-13 02:43:25,242 - INFO - allennlp.training.trainer - BERT.embeddings.LayerNorm.bias\n",
      "2019-05-13 02:43:25,242 - INFO - allennlp.training.trainer - BERT.encoder.layer.0.attention.self.query.weight\n",
      "2019-05-13 02:43:25,242 - INFO - allennlp.training.trainer - BERT.encoder.layer.0.attention.self.query.bias\n",
      "2019-05-13 02:43:25,242 - INFO - allennlp.training.trainer - BERT.encoder.layer.0.attention.self.key.weight\n",
      "2019-05-13 02:43:25,242 - INFO - allennlp.training.trainer - BERT.encoder.layer.0.attention.self.key.bias\n",
      "2019-05-13 02:43:25,242 - INFO - allennlp.training.trainer - BERT.encoder.layer.0.attention.self.value.weight\n",
      "2019-05-13 02:43:25,242 - INFO - allennlp.training.trainer - BERT.encoder.layer.0.attention.self.value.bias\n",
      "2019-05-13 02:43:25,243 - INFO - allennlp.training.trainer - BERT.encoder.layer.0.attention.output.dense.weight\n",
      "2019-05-13 02:43:25,243 - INFO - allennlp.training.trainer - BERT.encoder.layer.0.attention.output.dense.bias\n",
      "2019-05-13 02:43:25,243 - INFO - allennlp.training.trainer - BERT.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "2019-05-13 02:43:25,243 - INFO - allennlp.training.trainer - BERT.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "2019-05-13 02:43:25,243 - INFO - allennlp.training.trainer - BERT.encoder.layer.0.intermediate.dense.weight\n",
      "2019-05-13 02:43:25,243 - INFO - allennlp.training.trainer - BERT.encoder.layer.0.intermediate.dense.bias\n",
      "2019-05-13 02:43:25,243 - INFO - allennlp.training.trainer - BERT.encoder.layer.0.output.dense.weight\n",
      "2019-05-13 02:43:25,243 - INFO - allennlp.training.trainer - BERT.encoder.layer.0.output.dense.bias\n",
      "2019-05-13 02:43:25,243 - INFO - allennlp.training.trainer - BERT.encoder.layer.0.output.LayerNorm.weight\n",
      "2019-05-13 02:43:25,243 - INFO - allennlp.training.trainer - BERT.encoder.layer.0.output.LayerNorm.bias\n",
      "2019-05-13 02:43:25,243 - INFO - allennlp.training.trainer - BERT.encoder.layer.1.attention.self.query.weight\n",
      "2019-05-13 02:43:25,243 - INFO - allennlp.training.trainer - BERT.encoder.layer.1.attention.self.query.bias\n",
      "2019-05-13 02:43:25,243 - INFO - allennlp.training.trainer - BERT.encoder.layer.1.attention.self.key.weight\n",
      "2019-05-13 02:43:25,243 - INFO - allennlp.training.trainer - BERT.encoder.layer.1.attention.self.key.bias\n",
      "2019-05-13 02:43:25,243 - INFO - allennlp.training.trainer - BERT.encoder.layer.1.attention.self.value.weight\n",
      "2019-05-13 02:43:25,243 - INFO - allennlp.training.trainer - BERT.encoder.layer.1.attention.self.value.bias\n",
      "2019-05-13 02:43:25,243 - INFO - allennlp.training.trainer - BERT.encoder.layer.1.attention.output.dense.weight\n",
      "2019-05-13 02:43:25,244 - INFO - allennlp.training.trainer - BERT.encoder.layer.1.attention.output.dense.bias\n",
      "2019-05-13 02:43:25,244 - INFO - allennlp.training.trainer - BERT.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "2019-05-13 02:43:25,244 - INFO - allennlp.training.trainer - BERT.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "2019-05-13 02:43:25,244 - INFO - allennlp.training.trainer - BERT.encoder.layer.1.intermediate.dense.weight\n",
      "2019-05-13 02:43:25,244 - INFO - allennlp.training.trainer - BERT.encoder.layer.1.intermediate.dense.bias\n",
      "2019-05-13 02:43:25,244 - INFO - allennlp.training.trainer - BERT.encoder.layer.1.output.dense.weight\n",
      "2019-05-13 02:43:25,244 - INFO - allennlp.training.trainer - BERT.encoder.layer.1.output.dense.bias\n",
      "2019-05-13 02:43:25,244 - INFO - allennlp.training.trainer - BERT.encoder.layer.1.output.LayerNorm.weight\n",
      "2019-05-13 02:43:25,244 - INFO - allennlp.training.trainer - BERT.encoder.layer.1.output.LayerNorm.bias\n",
      "2019-05-13 02:43:25,244 - INFO - allennlp.training.trainer - BERT.encoder.layer.2.attention.self.query.weight\n",
      "2019-05-13 02:43:25,244 - INFO - allennlp.training.trainer - BERT.encoder.layer.2.attention.self.query.bias\n",
      "2019-05-13 02:43:25,244 - INFO - allennlp.training.trainer - BERT.encoder.layer.2.attention.self.key.weight\n",
      "2019-05-13 02:43:25,244 - INFO - allennlp.training.trainer - BERT.encoder.layer.2.attention.self.key.bias\n",
      "2019-05-13 02:43:25,244 - INFO - allennlp.training.trainer - BERT.encoder.layer.2.attention.self.value.weight\n",
      "2019-05-13 02:43:25,244 - INFO - allennlp.training.trainer - BERT.encoder.layer.2.attention.self.value.bias\n",
      "2019-05-13 02:43:25,244 - INFO - allennlp.training.trainer - BERT.encoder.layer.2.attention.output.dense.weight\n",
      "2019-05-13 02:43:25,245 - INFO - allennlp.training.trainer - BERT.encoder.layer.2.attention.output.dense.bias\n",
      "2019-05-13 02:43:25,245 - INFO - allennlp.training.trainer - BERT.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "2019-05-13 02:43:25,245 - INFO - allennlp.training.trainer - BERT.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "2019-05-13 02:43:25,245 - INFO - allennlp.training.trainer - BERT.encoder.layer.2.intermediate.dense.weight\n",
      "2019-05-13 02:43:25,245 - INFO - allennlp.training.trainer - BERT.encoder.layer.2.intermediate.dense.bias\n",
      "2019-05-13 02:43:25,245 - INFO - allennlp.training.trainer - BERT.encoder.layer.2.output.dense.weight\n",
      "2019-05-13 02:43:25,245 - INFO - allennlp.training.trainer - BERT.encoder.layer.2.output.dense.bias\n",
      "2019-05-13 02:43:25,245 - INFO - allennlp.training.trainer - BERT.encoder.layer.2.output.LayerNorm.weight\n",
      "2019-05-13 02:43:25,245 - INFO - allennlp.training.trainer - BERT.encoder.layer.2.output.LayerNorm.bias\n",
      "2019-05-13 02:43:25,245 - INFO - allennlp.training.trainer - BERT.encoder.layer.3.attention.self.query.weight\n",
      "2019-05-13 02:43:25,245 - INFO - allennlp.training.trainer - BERT.encoder.layer.3.attention.self.query.bias\n",
      "2019-05-13 02:43:25,245 - INFO - allennlp.training.trainer - BERT.encoder.layer.3.attention.self.key.weight\n",
      "2019-05-13 02:43:25,245 - INFO - allennlp.training.trainer - BERT.encoder.layer.3.attention.self.key.bias\n",
      "2019-05-13 02:43:25,245 - INFO - allennlp.training.trainer - BERT.encoder.layer.3.attention.self.value.weight\n",
      "2019-05-13 02:43:25,245 - INFO - allennlp.training.trainer - BERT.encoder.layer.3.attention.self.value.bias\n",
      "2019-05-13 02:43:25,245 - INFO - allennlp.training.trainer - BERT.encoder.layer.3.attention.output.dense.weight\n",
      "2019-05-13 02:43:25,246 - INFO - allennlp.training.trainer - BERT.encoder.layer.3.attention.output.dense.bias\n",
      "2019-05-13 02:43:25,246 - INFO - allennlp.training.trainer - BERT.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "2019-05-13 02:43:25,246 - INFO - allennlp.training.trainer - BERT.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "2019-05-13 02:43:25,246 - INFO - allennlp.training.trainer - BERT.encoder.layer.3.intermediate.dense.weight\n",
      "2019-05-13 02:43:25,246 - INFO - allennlp.training.trainer - BERT.encoder.layer.3.intermediate.dense.bias\n",
      "2019-05-13 02:43:25,246 - INFO - allennlp.training.trainer - BERT.encoder.layer.3.output.dense.weight\n",
      "2019-05-13 02:43:25,246 - INFO - allennlp.training.trainer - BERT.encoder.layer.3.output.dense.bias\n",
      "2019-05-13 02:43:25,246 - INFO - allennlp.training.trainer - BERT.encoder.layer.3.output.LayerNorm.weight\n",
      "2019-05-13 02:43:25,246 - INFO - allennlp.training.trainer - BERT.encoder.layer.3.output.LayerNorm.bias\n",
      "2019-05-13 02:43:25,246 - INFO - allennlp.training.trainer - BERT.encoder.layer.4.attention.self.query.weight\n",
      "2019-05-13 02:43:25,246 - INFO - allennlp.training.trainer - BERT.encoder.layer.4.attention.self.query.bias\n",
      "2019-05-13 02:43:25,246 - INFO - allennlp.training.trainer - BERT.encoder.layer.4.attention.self.key.weight\n",
      "2019-05-13 02:43:25,246 - INFO - allennlp.training.trainer - BERT.encoder.layer.4.attention.self.key.bias\n",
      "2019-05-13 02:43:25,246 - INFO - allennlp.training.trainer - BERT.encoder.layer.4.attention.self.value.weight\n",
      "2019-05-13 02:43:25,246 - INFO - allennlp.training.trainer - BERT.encoder.layer.4.attention.self.value.bias\n",
      "2019-05-13 02:43:25,246 - INFO - allennlp.training.trainer - BERT.encoder.layer.4.attention.output.dense.weight\n",
      "2019-05-13 02:43:25,246 - INFO - allennlp.training.trainer - BERT.encoder.layer.4.attention.output.dense.bias\n",
      "2019-05-13 02:43:25,247 - INFO - allennlp.training.trainer - BERT.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "2019-05-13 02:43:25,247 - INFO - allennlp.training.trainer - BERT.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "2019-05-13 02:43:25,247 - INFO - allennlp.training.trainer - BERT.encoder.layer.4.intermediate.dense.weight\n",
      "2019-05-13 02:43:25,247 - INFO - allennlp.training.trainer - BERT.encoder.layer.4.intermediate.dense.bias\n",
      "2019-05-13 02:43:25,247 - INFO - allennlp.training.trainer - BERT.encoder.layer.4.output.dense.weight\n",
      "2019-05-13 02:43:25,247 - INFO - allennlp.training.trainer - BERT.encoder.layer.4.output.dense.bias\n",
      "2019-05-13 02:43:25,247 - INFO - allennlp.training.trainer - BERT.encoder.layer.4.output.LayerNorm.weight\n",
      "2019-05-13 02:43:25,247 - INFO - allennlp.training.trainer - BERT.encoder.layer.4.output.LayerNorm.bias\n",
      "2019-05-13 02:43:25,247 - INFO - allennlp.training.trainer - BERT.encoder.layer.5.attention.self.query.weight\n",
      "2019-05-13 02:43:25,247 - INFO - allennlp.training.trainer - BERT.encoder.layer.5.attention.self.query.bias\n",
      "2019-05-13 02:43:25,247 - INFO - allennlp.training.trainer - BERT.encoder.layer.5.attention.self.key.weight\n",
      "2019-05-13 02:43:25,247 - INFO - allennlp.training.trainer - BERT.encoder.layer.5.attention.self.key.bias\n",
      "2019-05-13 02:43:25,247 - INFO - allennlp.training.trainer - BERT.encoder.layer.5.attention.self.value.weight\n",
      "2019-05-13 02:43:25,247 - INFO - allennlp.training.trainer - BERT.encoder.layer.5.attention.self.value.bias\n",
      "2019-05-13 02:43:25,247 - INFO - allennlp.training.trainer - BERT.encoder.layer.5.attention.output.dense.weight\n",
      "2019-05-13 02:43:25,247 - INFO - allennlp.training.trainer - BERT.encoder.layer.5.attention.output.dense.bias\n",
      "2019-05-13 02:43:25,248 - INFO - allennlp.training.trainer - BERT.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "2019-05-13 02:43:25,248 - INFO - allennlp.training.trainer - BERT.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "2019-05-13 02:43:25,248 - INFO - allennlp.training.trainer - BERT.encoder.layer.5.intermediate.dense.weight\n",
      "2019-05-13 02:43:25,248 - INFO - allennlp.training.trainer - BERT.encoder.layer.5.intermediate.dense.bias\n",
      "2019-05-13 02:43:25,248 - INFO - allennlp.training.trainer - BERT.encoder.layer.5.output.dense.weight\n",
      "2019-05-13 02:43:25,248 - INFO - allennlp.training.trainer - BERT.encoder.layer.5.output.dense.bias\n",
      "2019-05-13 02:43:25,248 - INFO - allennlp.training.trainer - BERT.encoder.layer.5.output.LayerNorm.weight\n",
      "2019-05-13 02:43:25,248 - INFO - allennlp.training.trainer - BERT.encoder.layer.5.output.LayerNorm.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-13 02:43:25,248 - INFO - allennlp.training.trainer - BERT.encoder.layer.6.attention.self.query.weight\r\n",
      "2019-05-13 02:43:25,248 - INFO - allennlp.training.trainer - BERT.encoder.layer.6.attention.self.query.bias\r\n",
      "2019-05-13 02:43:25,248 - INFO - allennlp.training.trainer - BERT.encoder.layer.6.attention.self.key.weight\r\n",
      "2019-05-13 02:43:25,248 - INFO - allennlp.training.trainer - BERT.encoder.layer.6.attention.self.key.bias\r\n",
      "2019-05-13 02:43:25,248 - INFO - allennlp.training.trainer - BERT.encoder.layer.6.attention.self.value.weight\r\n",
      "2019-05-13 02:43:25,248 - INFO - allennlp.training.trainer - BERT.encoder.layer.6.attention.self.value.bias\r\n",
      "2019-05-13 02:43:25,248 - INFO - allennlp.training.trainer - BERT.encoder.layer.6.attention.output.dense.weight\r\n",
      "2019-05-13 02:43:25,248 - INFO - allennlp.training.trainer - BERT.encoder.layer.6.attention.output.dense.bias\r\n",
      "2019-05-13 02:43:25,248 - INFO - allennlp.training.trainer - BERT.encoder.layer.6.attention.output.LayerNorm.weight\r\n",
      "2019-05-13 02:43:25,249 - INFO - allennlp.training.trainer - BERT.encoder.layer.6.attention.output.LayerNorm.bias\r\n",
      "2019-05-13 02:43:25,249 - INFO - allennlp.training.trainer - BERT.encoder.layer.6.intermediate.dense.weight\r\n",
      "2019-05-13 02:43:25,249 - INFO - allennlp.training.trainer - BERT.encoder.layer.6.intermediate.dense.bias\r\n",
      "2019-05-13 02:43:25,249 - INFO - allennlp.training.trainer - BERT.encoder.layer.6.output.dense.weight\r\n",
      "2019-05-13 02:43:25,249 - INFO - allennlp.training.trainer - BERT.encoder.layer.6.output.dense.bias\r\n",
      "2019-05-13 02:43:25,249 - INFO - allennlp.training.trainer - BERT.encoder.layer.6.output.LayerNorm.weight\r\n",
      "2019-05-13 02:43:25,249 - INFO - allennlp.training.trainer - BERT.encoder.layer.6.output.LayerNorm.bias\r\n",
      "2019-05-13 02:43:25,249 - INFO - allennlp.training.trainer - BERT.encoder.layer.7.attention.self.query.weight\r\n",
      "2019-05-13 02:43:25,249 - INFO - allennlp.training.trainer - BERT.encoder.layer.7.attention.self.query.bias\r\n",
      "2019-05-13 02:43:25,249 - INFO - allennlp.training.trainer - BERT.encoder.layer.7.attention.self.key.weight\r\n",
      "2019-05-13 02:43:25,249 - INFO - allennlp.training.trainer - BERT.encoder.layer.7.attention.self.key.bias\r\n",
      "2019-05-13 02:43:25,249 - INFO - allennlp.training.trainer - BERT.encoder.layer.7.attention.self.value.weight\r\n",
      "2019-05-13 02:43:25,249 - INFO - allennlp.training.trainer - BERT.encoder.layer.7.attention.self.value.bias\r\n",
      "2019-05-13 02:43:25,249 - INFO - allennlp.training.trainer - BERT.encoder.layer.7.attention.output.dense.weight\r\n",
      "2019-05-13 02:43:25,249 - INFO - allennlp.training.trainer - BERT.encoder.layer.7.attention.output.dense.bias\r\n",
      "2019-05-13 02:43:25,249 - INFO - allennlp.training.trainer - BERT.encoder.layer.7.attention.output.LayerNorm.weight\r\n",
      "2019-05-13 02:43:25,250 - INFO - allennlp.training.trainer - BERT.encoder.layer.7.attention.output.LayerNorm.bias\r\n",
      "2019-05-13 02:43:25,250 - INFO - allennlp.training.trainer - BERT.encoder.layer.7.intermediate.dense.weight\r\n",
      "2019-05-13 02:43:25,250 - INFO - allennlp.training.trainer - BERT.encoder.layer.7.intermediate.dense.bias\r\n",
      "2019-05-13 02:43:25,250 - INFO - allennlp.training.trainer - BERT.encoder.layer.7.output.dense.weight\r\n",
      "2019-05-13 02:43:25,250 - INFO - allennlp.training.trainer - BERT.encoder.layer.7.output.dense.bias\r\n",
      "2019-05-13 02:43:25,250 - INFO - allennlp.training.trainer - BERT.encoder.layer.7.output.LayerNorm.weight\r\n",
      "2019-05-13 02:43:25,250 - INFO - allennlp.training.trainer - BERT.encoder.layer.7.output.LayerNorm.bias\r\n",
      "2019-05-13 02:43:25,250 - INFO - allennlp.training.trainer - BERT.encoder.layer.8.attention.self.query.weight\r\n",
      "2019-05-13 02:43:25,250 - INFO - allennlp.training.trainer - BERT.encoder.layer.8.attention.self.query.bias\r\n",
      "2019-05-13 02:43:25,250 - INFO - allennlp.training.trainer - BERT.encoder.layer.8.attention.self.key.weight\r\n",
      "2019-05-13 02:43:25,250 - INFO - allennlp.training.trainer - BERT.encoder.layer.8.attention.self.key.bias\r\n",
      "2019-05-13 02:43:25,250 - INFO - allennlp.training.trainer - BERT.encoder.layer.8.attention.self.value.weight\r\n",
      "2019-05-13 02:43:25,250 - INFO - allennlp.training.trainer - BERT.encoder.layer.8.attention.self.value.bias\r\n",
      "2019-05-13 02:43:25,250 - INFO - allennlp.training.trainer - BERT.encoder.layer.8.attention.output.dense.weight\r\n",
      "2019-05-13 02:43:25,250 - INFO - allennlp.training.trainer - BERT.encoder.layer.8.attention.output.dense.bias\r\n",
      "2019-05-13 02:43:25,250 - INFO - allennlp.training.trainer - BERT.encoder.layer.8.attention.output.LayerNorm.weight\r\n",
      "2019-05-13 02:43:25,250 - INFO - allennlp.training.trainer - BERT.encoder.layer.8.attention.output.LayerNorm.bias\r\n",
      "2019-05-13 02:43:25,251 - INFO - allennlp.training.trainer - BERT.encoder.layer.8.intermediate.dense.weight\r\n",
      "2019-05-13 02:43:25,251 - INFO - allennlp.training.trainer - BERT.encoder.layer.8.intermediate.dense.bias\r\n",
      "2019-05-13 02:43:25,251 - INFO - allennlp.training.trainer - BERT.encoder.layer.8.output.dense.weight\r\n",
      "2019-05-13 02:43:25,251 - INFO - allennlp.training.trainer - BERT.encoder.layer.8.output.dense.bias\r\n",
      "2019-05-13 02:43:25,251 - INFO - allennlp.training.trainer - BERT.encoder.layer.8.output.LayerNorm.weight\r\n",
      "2019-05-13 02:43:25,251 - INFO - allennlp.training.trainer - BERT.encoder.layer.8.output.LayerNorm.bias\r\n",
      "2019-05-13 02:43:25,251 - INFO - allennlp.training.trainer - BERT.encoder.layer.9.attention.self.query.weight\r\n",
      "2019-05-13 02:43:25,251 - INFO - allennlp.training.trainer - BERT.encoder.layer.9.attention.self.query.bias\r\n",
      "2019-05-13 02:43:25,251 - INFO - allennlp.training.trainer - BERT.encoder.layer.9.attention.self.key.weight\r\n",
      "2019-05-13 02:43:25,251 - INFO - allennlp.training.trainer - BERT.encoder.layer.9.attention.self.key.bias\r\n",
      "2019-05-13 02:43:25,251 - INFO - allennlp.training.trainer - BERT.encoder.layer.9.attention.self.value.weight\r\n",
      "2019-05-13 02:43:25,251 - INFO - allennlp.training.trainer - BERT.encoder.layer.9.attention.self.value.bias\r\n",
      "2019-05-13 02:43:25,251 - INFO - allennlp.training.trainer - BERT.encoder.layer.9.attention.output.dense.weight\r\n",
      "2019-05-13 02:43:25,251 - INFO - allennlp.training.trainer - BERT.encoder.layer.9.attention.output.dense.bias\r\n",
      "2019-05-13 02:43:25,251 - INFO - allennlp.training.trainer - BERT.encoder.layer.9.attention.output.LayerNorm.weight\r\n",
      "2019-05-13 02:43:25,251 - INFO - allennlp.training.trainer - BERT.encoder.layer.9.attention.output.LayerNorm.bias\r\n",
      "2019-05-13 02:43:25,252 - INFO - allennlp.training.trainer - BERT.encoder.layer.9.intermediate.dense.weight\r\n",
      "2019-05-13 02:43:25,252 - INFO - allennlp.training.trainer - BERT.encoder.layer.9.intermediate.dense.bias\r\n",
      "2019-05-13 02:43:25,252 - INFO - allennlp.training.trainer - BERT.encoder.layer.9.output.dense.weight\r\n",
      "2019-05-13 02:43:25,252 - INFO - allennlp.training.trainer - BERT.encoder.layer.9.output.dense.bias\r\n",
      "2019-05-13 02:43:25,252 - INFO - allennlp.training.trainer - BERT.encoder.layer.9.output.LayerNorm.weight\r\n",
      "2019-05-13 02:43:25,252 - INFO - allennlp.training.trainer - BERT.encoder.layer.9.output.LayerNorm.bias\r\n",
      "2019-05-13 02:43:25,252 - INFO - allennlp.training.trainer - BERT.encoder.layer.10.attention.self.query.weight\r\n",
      "2019-05-13 02:43:25,252 - INFO - allennlp.training.trainer - BERT.encoder.layer.10.attention.self.query.bias\r\n",
      "2019-05-13 02:43:25,252 - INFO - allennlp.training.trainer - BERT.encoder.layer.10.attention.self.key.weight\r\n",
      "2019-05-13 02:43:25,252 - INFO - allennlp.training.trainer - BERT.encoder.layer.10.attention.self.key.bias\r\n",
      "2019-05-13 02:43:25,252 - INFO - allennlp.training.trainer - BERT.encoder.layer.10.attention.self.value.weight\r\n",
      "2019-05-13 02:43:25,252 - INFO - allennlp.training.trainer - BERT.encoder.layer.10.attention.self.value.bias\r\n",
      "2019-05-13 02:43:25,252 - INFO - allennlp.training.trainer - BERT.encoder.layer.10.attention.output.dense.weight\r\n",
      "2019-05-13 02:43:25,252 - INFO - allennlp.training.trainer - BERT.encoder.layer.10.attention.output.dense.bias\r\n",
      "2019-05-13 02:43:25,252 - INFO - allennlp.training.trainer - BERT.encoder.layer.10.attention.output.LayerNorm.weight\r\n",
      "2019-05-13 02:43:25,252 - INFO - allennlp.training.trainer - BERT.encoder.layer.10.attention.output.LayerNorm.bias\r\n",
      "2019-05-13 02:43:25,252 - INFO - allennlp.training.trainer - BERT.encoder.layer.10.intermediate.dense.weight\r\n",
      "2019-05-13 02:43:25,253 - INFO - allennlp.training.trainer - BERT.encoder.layer.10.intermediate.dense.bias\r\n",
      "2019-05-13 02:43:25,253 - INFO - allennlp.training.trainer - BERT.encoder.layer.10.output.dense.weight\r\n",
      "2019-05-13 02:43:25,253 - INFO - allennlp.training.trainer - BERT.encoder.layer.10.output.dense.bias\r\n",
      "2019-05-13 02:43:25,253 - INFO - allennlp.training.trainer - BERT.encoder.layer.10.output.LayerNorm.weight\r\n",
      "2019-05-13 02:43:25,253 - INFO - allennlp.training.trainer - BERT.encoder.layer.10.output.LayerNorm.bias\r\n",
      "2019-05-13 02:43:25,253 - INFO - allennlp.training.trainer - BERT.encoder.layer.11.attention.self.query.weight\r\n",
      "2019-05-13 02:43:25,253 - INFO - allennlp.training.trainer - BERT.encoder.layer.11.attention.self.query.bias\r\n",
      "2019-05-13 02:43:25,253 - INFO - allennlp.training.trainer - BERT.encoder.layer.11.attention.self.key.weight\r\n",
      "2019-05-13 02:43:25,253 - INFO - allennlp.training.trainer - BERT.encoder.layer.11.attention.self.key.bias\r\n",
      "2019-05-13 02:43:25,253 - INFO - allennlp.training.trainer - BERT.encoder.layer.11.attention.self.value.weight\r\n",
      "2019-05-13 02:43:25,253 - INFO - allennlp.training.trainer - BERT.encoder.layer.11.attention.self.value.bias\r\n",
      "2019-05-13 02:43:25,253 - INFO - allennlp.training.trainer - BERT.encoder.layer.11.attention.output.dense.weight\r\n",
      "2019-05-13 02:43:25,253 - INFO - allennlp.training.trainer - BERT.encoder.layer.11.attention.output.dense.bias\r\n",
      "2019-05-13 02:43:25,253 - INFO - allennlp.training.trainer - BERT.encoder.layer.11.attention.output.LayerNorm.weight\r\n",
      "2019-05-13 02:43:25,253 - INFO - allennlp.training.trainer - BERT.encoder.layer.11.attention.output.LayerNorm.bias\r\n",
      "2019-05-13 02:43:25,253 - INFO - allennlp.training.trainer - BERT.encoder.layer.11.intermediate.dense.weight\r\n",
      "2019-05-13 02:43:25,254 - INFO - allennlp.training.trainer - BERT.encoder.layer.11.intermediate.dense.bias\r\n",
      "2019-05-13 02:43:25,254 - INFO - allennlp.training.trainer - BERT.encoder.layer.11.output.dense.weight\r\n",
      "2019-05-13 02:43:25,254 - INFO - allennlp.training.trainer - BERT.encoder.layer.11.output.dense.bias\r\n",
      "2019-05-13 02:43:25,254 - INFO - allennlp.training.trainer - BERT.encoder.layer.11.output.LayerNorm.weight\r\n",
      "2019-05-13 02:43:25,254 - INFO - allennlp.training.trainer - BERT.encoder.layer.11.output.LayerNorm.bias\r\n",
      "2019-05-13 02:43:25,254 - INFO - allennlp.training.trainer - BERT.pooler.dense.weight\r\n",
      "2019-05-13 02:43:25,254 - INFO - allennlp.training.trainer - BERT.pooler.dense.bias\r\n",
      "2019-05-13 02:43:25,254 - INFO - allennlp.training.trainer - _passage_weights_predictor.weight\r\n",
      "2019-05-13 02:43:25,254 - INFO - allennlp.training.trainer - _passage_weights_predictor.bias\r\n",
      "2019-05-13 02:43:25,254 - INFO - allennlp.training.trainer - _question_weights_predictor.weight\r\n",
      "2019-05-13 02:43:25,254 - INFO - allennlp.training.trainer - _question_weights_predictor.bias\r\n",
      "2019-05-13 02:43:25,254 - INFO - allennlp.training.trainer - _number_weights_predictor.weight\r\n",
      "2019-05-13 02:43:25,254 - INFO - allennlp.training.trainer - _number_weights_predictor.bias\r\n",
      "2019-05-13 02:43:25,254 - INFO - allennlp.training.trainer - _arithmetic_weights_predictor.weight\r\n",
      "2019-05-13 02:43:25,254 - INFO - allennlp.training.trainer - _arithmetic_weights_predictor.bias\r\n",
      "2019-05-13 02:43:25,254 - INFO - allennlp.training.trainer - _answer_ability_predictor.0.weight\r\n",
      "2019-05-13 02:43:25,255 - INFO - allennlp.training.trainer - _answer_ability_predictor.0.bias\r\n",
      "2019-05-13 02:43:25,255 - INFO - allennlp.training.trainer - _answer_ability_predictor.3.weight\r\n",
      "2019-05-13 02:43:25,255 - INFO - allennlp.training.trainer - _answer_ability_predictor.3.bias\r\n",
      "2019-05-13 02:43:25,255 - INFO - allennlp.training.trainer - _passage_span_start_predictor.weight\r\n",
      "2019-05-13 02:43:25,255 - INFO - allennlp.training.trainer - _passage_span_start_predictor.bias\r\n",
      "2019-05-13 02:43:25,255 - INFO - allennlp.training.trainer - _passage_span_end_predictor.weight\r\n",
      "2019-05-13 02:43:25,255 - INFO - allennlp.training.trainer - _passage_span_end_predictor.bias\r\n",
      "2019-05-13 02:43:25,255 - INFO - allennlp.training.trainer - _question_span_start_predictor.0.weight\r\n",
      "2019-05-13 02:43:25,255 - INFO - allennlp.training.trainer - _question_span_start_predictor.0.bias\r\n",
      "2019-05-13 02:43:25,255 - INFO - allennlp.training.trainer - _question_span_start_predictor.3.weight\r\n",
      "2019-05-13 02:43:25,255 - INFO - allennlp.training.trainer - _question_span_start_predictor.3.bias\r\n",
      "2019-05-13 02:43:25,255 - INFO - allennlp.training.trainer - _question_span_end_predictor.0.weight\r\n",
      "2019-05-13 02:43:25,255 - INFO - allennlp.training.trainer - _question_span_end_predictor.0.bias\r\n",
      "2019-05-13 02:43:25,255 - INFO - allennlp.training.trainer - _question_span_end_predictor.3.weight\r\n",
      "2019-05-13 02:43:25,255 - INFO - allennlp.training.trainer - _question_span_end_predictor.3.bias\r\n",
      "2019-05-13 02:43:25,255 - INFO - allennlp.training.trainer - _qspan_passage_weight_predictor.weight\r\n",
      "2019-05-13 02:43:25,255 - INFO - allennlp.training.trainer - _qspan_passage_weight_predictor.bias\r\n",
      "2019-05-13 02:43:25,256 - INFO - allennlp.training.trainer - special_embedding.weight\r\n",
      "2019-05-13 02:43:25,256 - INFO - allennlp.training.trainer - _number_sign_predictor.0.weight\r\n",
      "2019-05-13 02:43:25,256 - INFO - allennlp.training.trainer - _number_sign_predictor.0.bias\r\n",
      "2019-05-13 02:43:25,256 - INFO - allennlp.training.trainer - _number_sign_predictor.3.weight\r\n",
      "2019-05-13 02:43:25,256 - INFO - allennlp.training.trainer - _number_sign_predictor.3.bias\r\n",
      "2019-05-13 02:43:25,256 - INFO - allennlp.training.trainer - _arithmetic_passage_weight_predictor.weight\r\n",
      "2019-05-13 02:43:25,256 - INFO - allennlp.training.trainer - _arithmetic_passage_weight_predictor.bias\r\n",
      "2019-05-13 02:43:25,256 - INFO - allennlp.training.trainer - _count_number_predictor.0.weight\r\n",
      "2019-05-13 02:43:25,256 - INFO - allennlp.training.trainer - _count_number_predictor.0.bias\r\n",
      "2019-05-13 02:43:25,256 - INFO - allennlp.training.trainer - _count_number_predictor.3.weight\r\n",
      "2019-05-13 02:43:25,256 - INFO - allennlp.training.trainer - _count_number_predictor.3.bias\r\n",
      "2019-05-13 02:43:25,256 - INFO - allennlp.training.trainer - _count_passage_weight_predictor.weight\r\n",
      "2019-05-13 02:43:25,256 - INFO - allennlp.training.trainer - _count_passage_weight_predictor.bias\r\n",
      "2019-05-13 02:43:25,256 - INFO - allennlp.common.params - trainer.patience = 10\r\n",
      "2019-05-13 02:43:25,256 - INFO - allennlp.common.params - trainer.validation_metric = +f1\r\n",
      "2019-05-13 02:43:25,256 - INFO - allennlp.common.params - trainer.shuffle = True\r\n",
      "2019-05-13 02:43:25,257 - INFO - allennlp.common.params - trainer.num_epochs = 20\r\n",
      "2019-05-13 02:43:25,257 - INFO - allennlp.common.params - trainer.cuda_device = 3\r\n",
      "2019-05-13 02:43:25,257 - INFO - allennlp.common.params - trainer.grad_norm = None\r\n",
      "2019-05-13 02:43:25,257 - INFO - allennlp.common.params - trainer.grad_clipping = None\r\n",
      "2019-05-13 02:43:25,257 - INFO - allennlp.common.params - trainer.learning_rate_scheduler = None\r\n",
      "2019-05-13 02:43:25,257 - INFO - allennlp.common.params - trainer.momentum_scheduler = None\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-13 02:43:29,260 - INFO - allennlp.common.params - trainer.optimizer.type = bert_adam\n",
      "2019-05-13 02:43:29,261 - INFO - allennlp.common.params - trainer.optimizer.parameter_groups = None\n",
      "2019-05-13 02:43:29,261 - INFO - allennlp.training.optimizers - Number of trainable parameters: 114818333\n",
      "2019-05-13 02:43:29,263 - INFO - allennlp.common.params - trainer.optimizer.infer_type_and_cast = True\n",
      "2019-05-13 02:43:29,263 - INFO - allennlp.common.params - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.\n",
      "2019-05-13 02:43:29,263 - INFO - allennlp.common.params - CURRENTLY DEFINED PARAMETERS: \n",
      "2019-05-13 02:43:29,263 - INFO - allennlp.common.params - trainer.optimizer.lr = 1e-05\n",
      "2019-05-13 02:43:29,263 - WARNING - pytorch_pretrained_bert.optimization - t_total value of -1 results in schedule not being applied\n",
      "2019-05-13 02:43:29,263 - INFO - allennlp.common.params - trainer.num_serialized_models_to_keep = 20\n",
      "2019-05-13 02:43:29,263 - INFO - allennlp.common.params - trainer.keep_serialized_model_every_num_seconds = 3600\n",
      "2019-05-13 02:43:29,264 - INFO - allennlp.common.params - trainer.model_save_interval = None\n",
      "2019-05-13 02:43:29,264 - INFO - allennlp.common.params - trainer.summary_interval = 100\n",
      "2019-05-13 02:43:29,264 - INFO - allennlp.common.params - trainer.histogram_interval = None\n",
      "2019-05-13 02:43:29,264 - INFO - allennlp.common.params - trainer.should_log_parameter_statistics = True\n",
      "2019-05-13 02:43:29,264 - INFO - allennlp.common.params - trainer.should_log_learning_rate = False\n",
      "2019-05-13 02:43:29,264 - INFO - allennlp.common.params - trainer.log_batch_size_period = None\n",
      "2019-05-13 02:43:29,302 - INFO - allennlp.training.trainer - Beginning training.\n",
      "2019-05-13 02:43:29,302 - INFO - allennlp.training.trainer - Epoch 0/19\n",
      "2019-05-13 02:43:29,303 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 5470.948\n",
      "2019-05-13 02:43:29,417 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 8769\n",
      "2019-05-13 02:43:29,417 - INFO - allennlp.training.trainer - GPU 1 memory usage MB: 9153\n",
      "2019-05-13 02:43:29,417 - INFO - allennlp.training.trainer - GPU 2 memory usage MB: 8769\n",
      "2019-05-13 02:43:29,417 - INFO - allennlp.training.trainer - GPU 3 memory usage MB: 839\n",
      "2019-05-13 02:43:29,420 - INFO - allennlp.training.trainer - Training\n",
      "em: 0.3147, f1: 0.3535, loss: 485844.7692 ||: 100%|##########| 19353/19353 [4:54:22<00:00,  1.21it/s]  \n",
      "2019-05-13 07:37:51,817 - INFO - allennlp.training.trainer - Validating\n",
      "em: 0.5136, f1: 0.5481, loss: 692116.2754 ||: 100%|##########| 2384/2384 [08:03<00:00,  5.64it/s]\n",
      "2019-05-13 07:45:55,395 - INFO - allennlp.training.tensorboard_writer -                     Training |  Validation\n",
      "2019-05-13 07:45:55,395 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB |  8769.000  |       N/A\n",
      "2019-05-13 07:45:55,396 - INFO - allennlp.training.tensorboard_writer - em              |     0.315  |     0.514\n",
      "2019-05-13 07:45:55,396 - INFO - allennlp.training.tensorboard_writer - f1              |     0.354  |     0.548\n",
      "2019-05-13 07:45:55,396 - INFO - allennlp.training.tensorboard_writer - gpu_2_memory_MB |  8769.000  |       N/A\n",
      "2019-05-13 07:45:55,397 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB   |  5470.948  |       N/A\n",
      "2019-05-13 07:45:55,397 - INFO - allennlp.training.tensorboard_writer - gpu_3_memory_MB |   839.000  |       N/A\n",
      "2019-05-13 07:45:55,397 - INFO - allennlp.training.tensorboard_writer - loss            |  485844.769  |  692116.275\n",
      "2019-05-13 07:45:55,397 - INFO - allennlp.training.tensorboard_writer - gpu_1_memory_MB |  9153.000  |       N/A\n",
      "2019-05-13 07:45:56,569 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to '/home/ubuntu/storage/nabert_newvector-extra-attn/best.th'.\n",
      "2019-05-13 07:45:56,977 - INFO - allennlp.training.trainer - Epoch duration: 05:02:27\n",
      "2019-05-13 07:45:56,977 - INFO - allennlp.training.trainer - Estimated training time remaining: 3 days, 23:46:45\n",
      "2019-05-13 07:45:56,977 - INFO - allennlp.training.trainer - Epoch 1/19\n",
      "2019-05-13 07:45:56,977 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 6175.64\n",
      "2019-05-13 07:45:57,065 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 8893\n",
      "2019-05-13 07:45:57,065 - INFO - allennlp.training.trainer - GPU 1 memory usage MB: 10663\n",
      "2019-05-13 07:45:57,065 - INFO - allennlp.training.trainer - GPU 2 memory usage MB: 8893\n",
      "2019-05-13 07:45:57,065 - INFO - allennlp.training.trainer - GPU 3 memory usage MB: 10663\n",
      "2019-05-13 07:45:57,067 - INFO - allennlp.training.trainer - Training\n",
      "em: 0.4522, f1: 0.4930, loss: 485658.4173 ||:  50%|####9     | 9621/19353 [2:25:46<2:15:43,  1.19it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "em: 0.4605, f1: 0.5015, loss: 487131.8043 ||:  93%|#########3| 18065/19353 [4:34:13<20:55,  1.03it/s]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "em: 0.4609, f1: 0.5020, loss: 487417.4233 ||:  95%|#########5| 18475/19353 [4:40:25<12:50,  1.14it/s]"
     ]
    }
   ],
   "source": [
    "!allennlp train /home/ubuntu/drop_bert/nabert_newvector-extra-attn.json -s /home/ubuntu/storage/nabert_newvector-extra-attn --include-package drop_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
